---
title: "Martinez_Sequera_Amelia_RMM_PEC1"
author: "Amelia Martínez Sequera"
date: "Abril 2020"
---

```{r setup, include=T}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
alcohol0 <- read_table2("alcohol.txt",skip = 1)
colnames(alcohol0)<-c("Metabol", "Gastric", "Sex", "Alcohol")
View(alcohol0)
str(alcohol0)
```

## Problema 1
```{r}
as.factor(alcohol0$Sex)
as.factor(alcohol0$Alcohol)
Male<-c(rep(0,17), rep(1,14))
Female<- c(rep(1,17), rep(0,14))
Alcoholic <- c(1,1,rep(0,15),rep(1,5),rep(0,9))
alcohol<- cbind(alcohol0, Male, Female, Alcoholic)
head(alcohol)

```

# Diferencias de Metabol entre hombres y mujeres
```{r}
library(faraway)
M1<- lm(Metabol~Gastric+Female, data=alcohol )
M2<- lm(Metabol~Gastric+Male, data=alcohol)
M3<- lm(Metabol~Gastric+Male+Female, data=alcohol)
M4<- lm(Metabol~0+Gastric+Male+Female, data=alcohol)
```
Vemos gráficamente con un diagrama de cajas que existen diferencias. Si construimos un modelo con la variable Sex, es el coeficiente de ésta la que nos muestra la diferencia entre ambos sexos:
```{r}
M<- lm(Metabol~Gastric+Sex, data=alcohol)
boxplot(Metabol~Sex, alcohol, col=c("pink", "lightblue"))
M$coefficients
```

#Mejor modelo según coeficiente de determinación: 
M4, R-Squared=0.87, explica mayor porcentaje de varianza.
```{r}
sumary(M1);sumary(M2); sumary(M3); sumary(M4)
```
Mejor modelo según RMSE: Todos tienen el mismo valor.

# Rango M3
```{r}
X<- model.matrix(~Gastric+Male+Female, data = alcohol)
Y<- alcohol$Metabol
qr(X)$rank
```
No podemos calcular la inversa  de X´X porque es una matriz singular. 
El rango de x (matriz del modelo M3) es 3, ya que las variables Male y Female son linealmente dependientes.

Utilizamos la inversa de Moore-Penrose:

```{r}
library(matlib)
Xtxi<- Ginv (t(X)%*% X)
coef<- Xtxi%*%t(X)%*%Y
coef; M3$coefficients
```
Los coeficientes son los mismos. Se desestima la variable Female porque es una combinación lineal de Male.

# Residuos: 
También coinciden.Los restamos para ver que la diferencia es 0
```{r}
M3sum<- summary(M3)
```
```{r}
residuals<- Y-X %*% coef
head(round(residuals-M3sum$residuals,4))
```

# Intervalos de confianza para beta0+beta1 en M2 al 95%
Hipótesis nula: 2alpha-beta0-beta1=0
```{r}
M2sum<- summary(M2)
X2<- model.matrix(~Gastric+Male, alcohol)
betas<- Ginv(t(X2) %*% X2) %*% t(X2) %*% Y
```

Residuos, sigma:
```{r}
res<- Y-X2 %*% betas
n<- length(Y)
r<- qr(X2)$rank
sigma2<- sum(res^2)/(n-r)
```
t Student:
```{r}
a <- c(2,-1,-1)
numerador <- t(a) %*% betas
denominador <- sqrt(sigma2 * t(a) %*% Ginv(t(X2) %*% X2) %*% a)
t.est <- numerador/denominador
p.value <- pt(abs(t.est), df = n-r, lower.tail = F) * 2
c(t.est,p.value)
```
```{r}
qt(0.975, n-r)
betas;M2sum$coefficients
(1.979401-2.002703)+c(-1,1)*2.048407*(0.541924+0.2728908)
```
Como elintervalo contiene el 0, la hipótesis nula no sería rechazada para una significación del 5%.

# Rectas de regresión:
```{r}
sex<- as.factor(alcohol$Sex)
levels(sex)
plot(Metabol~0+Gastric, pch=ifelse(sex=="Male",1,16),data=alcohol)
M12<-lm(Metabol~0+Gastric+Female, data=alcohol)
M22<- lm(Metabol~0+Gastric+Male, data=alcohol)
abline(M22, lty=1, col="blue")
abline(M12, lty=2, col="red")
```
```{r}
library(car)
scatterplot(Metabol~Gastric|sex, data=alcohol)
```
#Contraste de coincidencia:

```{r}
r1<- lm(Metabol~Gastric*Sex, data = alcohol)
r1
```
#Contraste paralelismo:

Suponiendo que las rectas estan a sociadas a un modelo lineal normal, planteamos la hipótesis nula de que los coeficientes de la variable Gastric (pendiente) son iguales en los 2 casos(hombre/mujer):
```{r}
r2<- lm(Metabol~Gastric+Sex, data=alcohol)
anova(r2,r1)
```
Se rechaza la hipótesis. No son paralelas

#Significación de  la variable concomitante(Metabol):
```{r}
anova(r2)
```
# Modelo completo
```{r}
MC<- lm(Metabol~Gastric+Male+Alcoholic+Gastric*Male+Gastric*Alcoholic+Male*Alcoholic+Gastric*Male*Alcoholic, data=alcohol)
MCsum<- summary(MC)
M2sum<- summary(M2)
MCsum$r.squared; M2sum$r.squared;MCsum$sigma; M2sum$sigma
```
El modelo completo mejora los resultados de R-Squared, explica mayor porcentaje de la varianza.
```{r}
plot(MC)
```
```{r}
anova(M2,MC)
```
De todas maneras, si comparamos ambos modelos vemos que por el momento no podemor rechazar la hipótesis nula. M2 sigue siendo aceptable.


## Problema 2
```{r}
library(readr)
senic <- read_table2("C:\\Users\\Meli\\Documents\\UOC\\Regres.mod.met\\PEC1_RMM\\senic.txt")
View(senic)
str(senic)
```

# Matriz de correlaciones
```{r}
head(senic[,-c(1,8,9,12)])
senic_cor<- cor(senic[,-c(1,8,9,12)])
senic_cor
library(corrplot)
corrplot(senic_cor, method= "square",type="lower", diag=F, addCoef.col = "black",number.cex = 0.6)

```

Las variables census, nurses y nbeds están muy correlacionadas entre sí. No se han incluido las variables categóricas: medschl y region. Son variables categóricas pero codificadas numéricamente, tanto medschl(1=si, 2=no), como region(1=NE, 2=NC, 3=S, 4=W). La variable medschl explica, por ejemplo, cuánto valdrá más la variable explicada para los no afiliados(el doble).


#Boxplot
```{r}
boxplot(infrisk~medschl, senic)
boxplot(infrisk~region, senic, col=c("lightblue","lightgreen","pink","yellow"))
```
1=NE, 2=NC, 3=S, 4=W

# ANOVA
consideramos como hipótesis nula que el coeficiente de la variable medschl es igual a 0 (no influye en el riesgo de infección)

```{r}
lmod<- lm(infrisk~stay+age+culratio+xratio+nbeds+medschl+region+census+nurses+service, data=senic)
lmod2<- lm(infrisk~stay+age+culratio+xratio+nbeds+region+census+nurses+service, data = senic)
anova(lmod2,lmod)
```
No podemos rechazar la hipótesis nula (p-value= 0.08) a un 0.05 de significación, pero sí a un 0.01.

Ahora, consideramos como hipótesis nula que el coeficiente de region es 0 (la región no influye en el riesgo de infección)
```{r}
lmod3<- lm(infrisk~stay+age+culratio+xratio+nbeds+medschl+census+nurses+service, data = senic)
anova(lmod3, lmod)
```
En este caso si que rechazamos la hipótesis nula (p= 0.005324). La región influye en el valor de infrisk.

# Modelo
```{r}
lmod<- lm(infrisk~stay+age+culratio+xratio+nbeds+medschl+region+census+nurses+service, data=senic)
summary(lmod)
```
Stay y culratio son la variables predictoras más significativas. La variable region también tiene un nivel de significación alto pero, como se ha mencionado anteriormente, es una variable categórica, igual que medschl, que toman valores numéricos (1,2,3,4). 


El modelo también nos da el valor del F-test, y un valor de p-value que es significativo. La hipótesis nula es que la media es la misma para los diferentes grupos de análisis y la hipótesis alternativa es que, al menos, dos medias de los diferentes grupos, difieren. 


Predictoras significativas al 5%:
```{r}
summary(lmod)$coef[,4]<0.05
```

# Modelo - variables con significación <5% (lmodb)

```{r}
summary(lmod)$coef[,4]<0.05
```
Contraste frente al completo: hipótesis nula: los coeficientes de las variables con significación <5% son igual a 0.

```{r}
lmodb<- lm(infrisk~stay+culratio+xratio+region+service, data=senic)
anova (lmodb, lmod)
```
No rechazamos de momento la hipótesis nula. El modelo reducido es una buena opción.

También podemos calcularlos intervalos de confianza al 95% de los parámetros de cada variable, y descartar aquellas en que su intervalo contiene el 0.
```{r}
confint(lmod)
```
Obtendríamos el mismo modelo lmodb.


# Modelo con stay, culratio y region (lmodc). Normalidad y heterocedasticidad. Gráficos.

```{r}
lmodc<- lm(infrisk~stay+culratio+region, data=senic)
lmodcsum<-summary(lmodc)
mean(lmodcsum$residuals);lmodcsum$sigma;cor(fitted(lmodc),lmodcsum$residuals)
```
Observamos que el valor medio de los residuos es casi cero. 
Se espera que los residuos sean independientes de la variable explicativa y del modelo ajustado, que la varianza sea constante, y que sigan una distribución normal. De no ser así podríamos suponer que el modelo no está bien ajustado o que faltan predictores.

#Homocedasticidad: igualdad en la varianza de los errores.

```{r}
plot(fitted(lmodc),residuals(lmodc), xlab="predict values", ylab="residuals")
abline(h=0)
```

No se ven muy uniformes. Puede ser útil hacer la transformación de la raíz cuadrada de la respuesta:
```{r}
lmodc2 <- lm(sqrt(infrisk) ~stay+culratio+region, data=senic)
plot(fitted(lmodc2),residuals(lmodc2),xlab="Fitted",ylab="Residuals")
abline(h=0)
library(faraway)
```

```{r}
sumary(lm(sqrt(abs(residuals(lmodc)))~fitted(lmodc)))
```

El gráfico nos muestra una varianza no-lineal. El valor de p(>0.05) indica que no existe una relación significativa. 

#Normalidad:
```{r}
qqnorm(residuals(lmodc),ylab="Residuals")
qqline(residuals(lmodc))
```
```{r}
shapiro.test(residuals(lmodc))
```
Ni gráficamente ni por el test de contraste, vemos que la distribución de los residuos se aparte mucho de la normal.La hipótesis del test es que los residuos son normales, y por el valor de p no podemos rechazarla.

#Leverage:

observaciones con el leverage más alto:
```{r}
hatv <- hatvalues(lmodc  )
head(sort(hatv,decreasing=T)); sum(hatv)
```
Gráficamente:
```{r}
pc <- length(lmodc$coefficients)
nc <- length(lmodc$fitted.values)
leverage.mean <- pc/nc
plot(hatv, type="h")
abline(h=2*leverage.mean, col="red")
```

Comprobamos de ambas maneras que las observaciones con un leverage más alto son la 47, 8 y 112.


#Son outliers? consideramos el valor crítico de la t de Student y la corrección de Bonferroni. Nivel de significación 5%.
```{r}
stud<- rstandard(lmodc)
grlib <- nc-pc-1
head(sort(abs(stud), decreasing = T)); grlib
which(abs(stud) > abs(qt(0.05/(2*nc),grlib)))
```
Con este último criterio, todos los residuos quedan por debajo del valor crítico, no hallamos ningún valor atípico. Queda la duda de si puede haber grupos de valores atípicos que no hayamos sabido encontrar.

#Observaciones influyentes:
Calculamos la distancia de Cook como medida de la influencia de los puntos y la representamos contra los cuartiles de una distribución seminormal.

```{r}
cook <- cooks.distance(lmodc)
halfnorm(cook,nlab=3,ylab="Distancia de Cook")
```

#Criterio de selección:
```{r}
plot(lmodc, which=4)
abline(h=4/((nc-pc-2)), col="red")
```

Vemos que las observaciones 8, 112 y 47 son las que tienen más influencia.

# Predicción del riesgo de infección (intervalo 90%) lmodc
stay= 9.6, cultratio= 15.5, region=NE, lmodc
```{r  }
class(senic$region)
p<- predict(lmodc, newdata = data.frame(stay= 9.6, culratio= 15.5, region=1), interval="prediction", level=0.9)
p
```
NE está codificado como valor numérico (1).
```{r}
xc<- model.matrix(~stay+culratio+region,data=senic)
yc<- senic$infrisk
dim(xc)
head(xc[,2:4])
```
1=NE, 2=NC, 3=S, 4=W

```{r}
summary(lmodc)
```

# Predicción manual stay y culratio (en este orden) 90%
```{r}
0.331548+c(-1,1)*qt(0.9,109)*0.057229
0.06+c(-1,1)*qt(0.9,109)*0.009781
```

# Modelo stay+age+xratio+medschl (modd), alpha=0.1
```{r}
modd<- lm(infrisk~stay+ age+ xratio+ medschl, data=senic)
summodd<- summary(modd)
corsenicb <- cor(senic[,-c(1,4,5,7,9,10,11,12)])
corsenicb; corrplot(corsenicb, method= "square",type="lower", diag=F, addCoef.col = "black",number.cex = 0.7)
```
No existe una gran correlación con age, y menos aún con xratio.

```{r}
cor.test(senic$medschl, senic$age); cor.test(senic$medschl, senic$xratio)
```

Comparamos este modelo (modd), con el mismo modelo pero: 1)considerando que hay interacción entre medschl y age, y 2) hay interacción entre medschl y xratio.

```{r}
modd1<- lm(infrisk~stay+age+xratio+medschl+medschl:age, data=senic)
anova(modd, modd1)
```
```{r}
modd2<- lm(infrisk~stay+age+xratio*medschl, data=senic)
anova(modd2,modd)
```

La hipótesis nula es que los términos de interacción son 0.A un nivel de significación alpha=0.1<p, no rechazamos la hipótesis nula. Se puede prescindir de los términos de interacción.
